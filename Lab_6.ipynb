{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Vincent Ning\n#10010690\n\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nimport tensorflow as tf\nfrom tensorflow import keras\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\nfrom sklearn.metrics import accuracy_score\nfrom functools import partial\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/housing.csv')\nmedian_num_bedrooms = df['total_bedrooms'].median()\ndf['total_bedrooms'].fillna(median_num_bedrooms, inplace=True)\nmissing_values_count = df.isnull().sum()\nmissing_values_count[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings('ignore')\nX = df.iloc[:, 1:-1]\ny = df.iloc[:, 9]\nX_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=1345375)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op_obj_df = df.select_dtypes(include=['object']).copy()\nreplace_map = {'ocean_proximity': {'NEAR BAY': 1, '<1H OCEAN': 2, 'NEAR OCEAN': 3, 'ISLAND': 4,\n                                  'INLAND':5}}\nlabels = op_obj_df['ocean_proximity'].astype('category').cat.categories.tolist()\nreplace_map_comp = {'ocean_proximity' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n\nop_obj_df_replace = op_obj_df.copy()\nop_obj_df_replace.replace(replace_map_comp, inplace=True)\n\nX_train_full['ocean_proximity'] = op_obj_df_replace['ocean_proximity']\nX_test['ocean_proximity'] = op_obj_df_replace['ocean_proximity']\n\nX_train_full.dtypes.sample(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1875, random_state=1345375)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After the experiment, 8 layers with 100 layer size has the best network"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential()\nmodel.add(keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(1))\n\nmodel.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics = [\"mae\"])\n\nhistory = model.fit(X_train, y_train, epochs=30, validation_data = (X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\nprint(len(preds[ preds < 15000 ]))\nprint(len(preds[ preds > 50000 ]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4119 test examples have predictions outside [15000, 500000]"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best MAE from lab 3 was 62325.8894. Our MAE from this lab is 39904.2647. It is a huge improvment of 22421.6247.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.datasets import cifar10\n(X_train_1, y_train_1), (X_test_1, y_test_1) = cifar10.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_1 = keras.utils.to_categorical(y_train_1)\ny_test_1 = keras.utils.to_categorical(y_test_1)\nX_train_1 = X_train_1/255\nX_test_1 = X_test_1/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, activation='relu', padding=\"SAME\")\nmodel_1 = keras.models.Sequential([    \n    DefaultConv2D(filters=64, kernel_size=7, input_shape=[32, 32, 3]),    \n    keras.layers.MaxPooling2D(pool_size=2),\n    DefaultConv2D(filters=128),    \n    DefaultConv2D(filters=128),\n    keras.layers.MaxPooling2D(pool_size=2),\n    DefaultConv2D(filters=256),\n    DefaultConv2D(filters=256),\n    keras.layers.MaxPooling2D(pool_size=2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(units=128, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(units=64, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(units=10, activation='softmax'),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel_1.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\nmodel_1.fit(X_train_1, y_train_1, epochs=15, validation_split=0.15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1.evaluate(X_test_1, y_test_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_1 = model_1.predict(X_test_1)\nprint(preds_1[7])\nprint(np.argmax(preds_1[7]))\nprint(np.argmax(y_test_1[7]))\npreds_1[7][np.argmax(preds_1[7])] - preds_1[7][ np.argmax(y_test_1[7])]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"margins = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nentries = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nfor i in range(len(preds_1)):\n    if np.argmax(preds_1[i]) != np.argmax(y_test_1[i]):\n        print(i)\n        currentMargin = preds_1[i][np.argmax(preds_1[i])] - preds_1[i ][ np.argmax(y_test_1[i])]\n        if currentMargin > margins[np.argmax(y_test_1[i])]:\n            margins[np.argmax(y_test_1[i])] = currentMargin\n            entries[np.argmax(y_test_1[i])] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(entries)\nprint(margins)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 0\nfor i in entries:\n    plt.title(\"Correct Label: \" + str(np.argmax(y_test_1[i])) + \"  Wrongly Predicted Label: \" + str(np.argmax(preds_1[i])) + \"  value of p_predicted-p_correct: \" + str(margins[index]))\n    plt.imshow(X_train_1[i])\n    plt.show()\n    index = index + 1\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}